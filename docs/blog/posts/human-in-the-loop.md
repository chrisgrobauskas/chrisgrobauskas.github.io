---
title: Human In The Loop
date: 
  created: 2023-09-09
  updated: 2025-04-06
authors: 
  - grobauskas
categories:
  - AI
---

What if an AI monitored whether you followed all rules and laws that applied to you?

This chilling and dystopian thought is the subject of a guest post by Jon Penney on Bruce Schneier’s blog (link at bottom).

<!-- more -->

### Key Points
1. The article is a good reminder of why there should be a “human in the loop” for higher-risk activities. This is not a new concept. Consider nuclear weapon launch procedures. Multiple people must carry out any order to launch because there are serious consequences.

Accusing someone of an illegal activity could carry serious consequences and should require a human in the loop.

2. Penney covers the legal risks to the targets of AI-based decisions, but one would hope legal risks will also exist for the owners of misbehaving AI systems.

While businesses need to carefully consider AI efforts on their technical and business merits, they also need to consider whether outcomes are fair and defensible in court.

### Example
Take, for example, an AI system that identifies potential fraud. Is the AI that made the recommendation accurate and free of error and bias? Can the recommendations the AI makes be explained? Was an actual decision made by the AI, or was it only a recommendation reviewed against other information?

Accusing someone of fraud is serious and could lead to a lawsuit or choosing not to fulfill an otherwise required action under a contract.

I am not a lawyer, but to me, a human in the loop making decisions based on a recommendation seems more defensible. The human can review the recommendation and hopefully catch errors.

What do you think? What systems need a human in the loop?

[AI and Micro-directives](https://www.schneier.com/blog/archives/2023/07/ai-and-microdirectives.html)

## ACM Generative AI Principles
The ACM Technology Policy Council agrees that responsibility is important. Human-In-The-Loop is just one type of responsibility. The ACM has published principles for generative AI. While good governance is less exciting than delivering new features, it is important for practitioners to be responsible and thoughtful in their work.

The most essential message in the document is listed last:

> "Accountability and responsibility: Public and private bodies should be held accountable for decisions made by algorithms they use, even if it is not feasible to explain in detail how those algorithms produced their results."

For the full document, browse through the following link:
[ACM Generative AI Principles](https://www.acm.org/binaries/content/assets/public-policy/ustpc-approved-generative-ai-principles)

